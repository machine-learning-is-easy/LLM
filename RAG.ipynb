{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc922e84-1024-42d0-9b2c-1c679e89250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"llama2.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"你是个问答机器人，你根据给定的知识回答用户问题。\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  file_ids=[file.id]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Llama 2\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"请用中文回答用户的问题。\",\n",
    ")\n",
    "\n",
    "while run.status != \"completed\":\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "for turn in reversed(messages.data):\n",
    "    print(f\"{turn.role.upper()}: \"+turn.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f1773-4d39-4918-ae15-16f341b08e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30616b4-d2b1-4f23-8440-553804b0dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74ac40-a05b-4958-959e-7f0decba0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filename, page_numbers=None, min_line_length=1):\n",
    "    paragraphs = []\n",
    "    buffer = ''\n",
    "    full_text = ''\n",
    "    for i, page_layout in enumerate(extract_pages(filename)):\n",
    "        if page_numbers is not None and i not in page_numbers:\n",
    "            continue\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                full_text += element.get_text() + '\\n'\n",
    "    lines = full_text.split('\\n')\n",
    "    for text in lines:\n",
    "        if len(text) >= min_line_length:\n",
    "            buffer += (' '+text) if not text.endswith('-') else text.strip('-')\n",
    "        elif buffer:\n",
    "            paragraphs.append(buffer)\n",
    "            buffer = ''\n",
    "    if buffer:\n",
    "        paragraphs.append(buffer)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224ab4f-1ef9-492e-9ae9-10cd43abf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = extract_text_from_pdf(\"llama2.pdf\", min_line_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453880f6-4724-43a0-b177-262a40261ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch7\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5544b7-14dc-4627-9fd2-6ccccceb75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch7 import Elasticsearch, helpers\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a0bcd-5ae0-4100-9928-824823acc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_keywords(input_string):\n",
    "    no_symbols = re.sub(r'[^a-zA-Z0-9\\s]', ' ', input_string)\n",
    "    word_tokens = word_tokenize(no_symbols)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    filtered_sentence = [ps.stem(w)\n",
    "                         for w in word_tokens if not w.lower() in stop_words]\n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100fd66-2fa9-4fde-87ec-c77698835156",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts=['ip address'], \n",
    "    http_auth=(\"elastic\", \"password\"), \n",
    ")\n",
    "\n",
    "index_name = \"string_index\"\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "es.indices.create(index=index_name)\n",
    "\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_source\": {\n",
    "            \"keywords\": to_keywords(para),\n",
    "            \"text\": para\n",
    "        }\n",
    "    }\n",
    "    for para in paragraphs\n",
    "]\n",
    "\n",
    "helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b1505-cb57-427d-935f-57bf45fdddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_string, top_n=3):\n",
    "    search_query = {\n",
    "        \"match\": {\n",
    "            \"keywords\": to_keywords(query_string)\n",
    "        }\n",
    "    }\n",
    "    res = es.search(index=index_name, query=search_query, size=top_n)\n",
    "    return [hit[\"_source\"][\"text\"] for hit in res[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248ee6f-273d-43b4-bc91-4ecdde2dfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search(\"how many parameters does llama 2 have?\", 2)\n",
    "for r in results:\n",
    "    print(r+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa181a-c649-487e-ae74-5461b8e372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12ecc8-a3f3-4335-a932-bb5f8dd00f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfae176-45c5-4ede-8a5f-80ccd701ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(prompt_template, **kwargs):\n",
    "    prompt = prompt_template\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, str):\n",
    "            val = v\n",
    "        elif isinstance(v, list) and all(isinstance(elem, str) for elem in v):\n",
    "            val = '\\n'.join(v)\n",
    "        else:\n",
    "            val = str(v)\n",
    "        prompt = prompt.replace(f\"__{k.upper()}__\", val)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05a9e8-1aae-4dcc-9466-b05bd54a22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"how many parameters does llama 2 have?\"\n",
    "\n",
    "search_results = search(user_query, 2)\n",
    "\n",
    "prompt = build_prompt(prompt_template, info=search_results, query=user_query)\n",
    "print(prompt)\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804f538-9cd9-4c80-86f2-eb07351dd2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
